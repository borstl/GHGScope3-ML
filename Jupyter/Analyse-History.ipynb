{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from data.cleaning import read_all_historic_csv\n",
    "from core import Config\n",
    "import pandas as pd\n",
    "\n",
    "config = Config()\n",
    "historic_dictionary: dict[str, pd.DataFrame] = read_all_historic_csv(config.historic_dir)\n",
    "all_historic_frame: pd.DataFrame = pd.concat(historic_dictionary.values())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "historic_counter: Counter = Counter()\n",
    "for dataframe in historic_dictionary.values():\n",
    "    historic_counter.update(dataframe.columns.to_list())\n",
    "most_common_historic_columns: list[tuple[str, int]] = historic_counter.most_common()\n",
    "historic_dictionary_len = len(historic_dictionary)\n",
    "del historic_dictionary"
   ],
   "id": "dbbebf967e6edc4b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "bar_data: pd.DataFrame = pd.DataFrame(most_common_historic_columns, columns=[\"Features\", \"sameFeatureCount\"])\n",
    "bar_data[\"sameFeatureCount\"] = bar_data[\"sameFeatureCount\"].apply(lambda x: x/historic_dictionary_len * 100)\n",
    "labels = [\"{0} - {1}\".format(i, i + 10) for i in range(0, 100, 10)]\n",
    "bar_data[\"companyCountIn%\"] = pd.cut(bar_data[\"sameFeatureCount\"], range(0, 101, 10), labels=labels, right=True)\n",
    "grouped: pd.DataFrame = bar_data.groupby(\"companyCountIn%\").count().reset_index(names=\"companyCountIn%\")\n",
    "grouped[\"companyCountIn%\"] = grouped[\"companyCountIn%\"].astype(str)\n",
    "mask = bar_data.loc[bar_data[\"sameFeatureCount\"] < 90, \"Features\"]\n",
    "all_historic_frame.drop(columns=mask, inplace=True)"
   ],
   "id": "bf1e937ac3360c97",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.express as px\n",
    "fig = px.bar(\n",
    "    grouped,\n",
    "    x=\"companyCountIn%\",\n",
    "    y=\"sameFeatureCount\",\n",
    "    color=\"sameFeatureCount\",\n",
    "    color_continuous_scale=\"mint\",\n",
    "    text_auto=True,\n",
    "    labels={\n",
    "        \"companyCountIn%\": \"Anzahl Unternehmen in %\",\n",
    "        \"sameFeatureCount\": \"Anzahl Ã¼berschneidender zeitreihen Features\",\n",
    "    }\n",
    ")\n",
    "fig.update_coloraxes(showscale=False)\n",
    "fig.write_image(config.data_dir / \"figures\" / \"historic-same-features-count.png\")\n",
    "fig.show()"
   ],
   "id": "8f617be0aa83f13c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# figure out the desired Scope 3.1 purchased goods and services value and how it was reported\n",
    "scope3_1_count_per_year: pd.Series = (\n",
    "    all_historic_frame[\"TR.UpstreamScope3PurchasedGoodsAndServices\"].notna().groupby(level=1).sum()\n",
    ")\n",
    "fig = px.bar(\n",
    "    scope3_1_count_per_year,\n",
    "    x=scope3_1_count_per_year.index,\n",
    "    y=\"TR.UpstreamScope3PurchasedGoodsAndServices\",\n",
    "    color=\"TR.UpstreamScope3PurchasedGoodsAndServices\",\n",
    "    color_continuous_scale=\"mint\",\n",
    "    text_auto=True,\n",
    "    labels={\n",
    "        \"TR.UpstreamScope3PurchasedGoodsAndServices\": \"Anzahl Reports von Scope 3.1\",\n",
    "        \"Date\": \"Jahr\",\n",
    "    }\n",
    ")\n",
    "fig.update_coloraxes(showscale=False)\n",
    "fig.write_image(config.data_dir / \"figures\" / \"scope3_1_count_per_year.png\")\n",
    "fig.show()"
   ],
   "id": "30255e84b90cace9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Working with filtered Dataset",
   "id": "6996d59472d57517"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from data.cleaning import read_all_historic_csv\n",
    "from core import Config\n",
    "import pandas as pd\n",
    "\n",
    "config = Config()\n",
    "filtered_historic_frame = pd.read_csv(config.filtered_dir / \"filtered_historic.csv\", index_col=[0, 1])"
   ],
   "id": "ee465c9135153ca4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Filter companies with many NaN values (over 83%)",
   "id": "a38986f0b802dd8b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T16:33:19.831730Z",
     "start_time": "2025-10-07T16:33:19.512215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nan_counts = filtered_historic_frame.isna().sum(axis=1).groupby(level=0).sum().sort_values(ascending=False)\n",
    "nan_counts.name = \"NaN Count\"\n",
    "# companies with NaN values over 83% (Why 83%? Because with 82% there would fall to many companies out of the data)\n",
    "companies_with_nan_over_83 = nan_counts[nan_counts > (filtered_historic_frame.shape[1] * (2024-2016+1)) * 0.83].to_frame()"
   ],
   "id": "2579d586a347c208",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T16:36:45.236666Z",
     "start_time": "2025-10-07T16:36:45.198592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import plotly.express as px\n",
    "labels = [\"{0} - {1}\".format(i, i + 10) for i in range(0, 100, 10)]\n",
    "bar_data = pd.DataFrame()\n",
    "bar_data[\"Nan Count\"] = pd.cut(companies_with_nan_over_83, range(0, 101, 10), labels=labels, right=True)\n",
    "fig = px.bar(\n",
    "    companies_with_nan_over_83,\n",
    "    x=companies_with_nan_over_83.index,\n",
    "    y=\"NaN Count\",\n",
    "    color=\"NaN Count\",\n",
    "    color_continuous_scale=\"mint\",\n",
    "    text_auto=True,\n",
    "    labels={\n",
    "        \"NaN Count\": \"Anzahl NaN Werte\",\n",
    "        \"Company\": \"Unternehmen\",\n",
    "    }\n",
    ")\n",
    "fig.show()"
   ],
   "id": "c0a242bd96f47d27",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input array must be 1 dimensional",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[44]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      2\u001B[39m labels = [\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[33m - \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[33m\"\u001B[39m.format(i, i + \u001B[32m10\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[32m0\u001B[39m, \u001B[32m100\u001B[39m, \u001B[32m10\u001B[39m)]\n\u001B[32m      3\u001B[39m bar_data = pd.DataFrame()\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m bar_data[\u001B[33m\"\u001B[39m\u001B[33mNan Count\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[43mpd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcut\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcompanies_with_nan_over_83\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mrange\u001B[39;49m\u001B[43m(\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m101\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m10\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mright\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m      5\u001B[39m fig = px.bar(\n\u001B[32m      6\u001B[39m     companies_with_nan_over_83,\n\u001B[32m      7\u001B[39m     x=companies_with_nan_over_83.index,\n\u001B[32m   (...)\u001B[39m\u001B[32m     15\u001B[39m     }\n\u001B[32m     16\u001B[39m )\n\u001B[32m     17\u001B[39m fig.show()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ML/lib/python3.13/site-packages/pandas/core/reshape/tile.py:242\u001B[39m, in \u001B[36mcut\u001B[39m\u001B[34m(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered)\u001B[39m\n\u001B[32m    239\u001B[39m \u001B[38;5;66;03m# NOTE: this binning code is changed a bit from histogram for var(x) == 0\u001B[39;00m\n\u001B[32m    241\u001B[39m original = x\n\u001B[32m--> \u001B[39m\u001B[32m242\u001B[39m x_idx = \u001B[43m_preprocess_for_cut\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    243\u001B[39m x_idx, _ = _coerce_to_type(x_idx)\n\u001B[32m    245\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np.iterable(bins):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ML/lib/python3.13/site-packages/pandas/core/reshape/tile.py:592\u001B[39m, in \u001B[36m_preprocess_for_cut\u001B[39m\u001B[34m(x)\u001B[39m\n\u001B[32m    590\u001B[39m     x = np.asarray(x)\n\u001B[32m    591\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m x.ndim != \u001B[32m1\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m592\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mInput array must be 1 dimensional\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    594\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m Index(x)\n",
      "\u001B[31mValueError\u001B[39m: Input array must be 1 dimensional"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Converting dtypes",
   "id": "7af66f9c42bf00a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "converted = filtered_historic_frame.convert_dtypes()\n",
    "g = converted.columns.to_series().groupby(converted.dtypes.apply(lambda x: x.name))\n",
    "converted[g.get_group(\"string\")] = converted[g.get_group(\"string\")].astype(\"category\")\n",
    "my_list = list(converted.select_dtypes(include='boolean').columns)\n",
    "types = list(converted.dtypes.values)"
   ],
   "id": "f657a3a9454675d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Impute values",
   "id": "b46aeb508f0bf34a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#remove values with only one unique value\n",
    "boolean_columns = converted.select_dtypes('bool').columns\n",
    "is_single_value = [\n",
    "    col for col in boolean_columns\n",
    "    if converted[col].dropna().nunique() == 1\n",
    "]\n",
    "for col in is_single_value:\n",
    "    print(f\"{converted[col].value_counts()}\")\n",
    "#is_single_value_df: pd.DataFrame = filtered_historic_frame_converted.loc[:, is_single_value]\n",
    "#filtered_historic_frame_converted.columns[is_single_value].dtype\n",
    "#filtered_historic_frame_converted.drop(columns=is_single_value_df.columns, inplace=True)"
   ],
   "id": "438d531eaa7cb711",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "boolean_cols = converted.select_dtypes('bool')\n",
    "summary = pd.DataFrame({\n",
    "    'True': boolean_cols.sum(),\n",
    "    'False': (~boolean_cols).sum()\n",
    "})"
   ],
   "id": "36506c04db666115",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Count NaN in the whole time series frame and filter\n",
    "nan_count: pd.Series = filtered_historic_frame.isna().sum()\n",
    "# filter how many NaN per year\n",
    "nan_per_year: pd.DataFrame = filtered_historic_frame.isna().groupby(level=1).sum()\n",
    "nan_per_year_and_column: pd.Series = nan_per_year.sum(axis=1)\n",
    "# filter features with threshold NaNs\n",
    "filtered: pd.DataFrame = filtered_historic_frame.drop(nan_count.index[nan_count > 15000], axis=1)"
   ],
   "id": "d462b40813c82363",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Write List of filterted features",
   "id": "c6c0b49ad70344d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "filtered_time_series_feature_list: list[str] = all_historic_frame.columns.to_list()\n",
    "filtered_time_series_feature_list.sort()\n",
    "with open(config.historic_features_file, \"w\") as file:\n",
    "    file.write(\"\\n\".join(str(i) for i in filtered_time_series_feature_list))"
   ],
   "id": "353b7465d6d00954",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# TODO\n",
    "- convert categorical data to category\n",
    "- Check how balanced categorical data is"
   ],
   "id": "ed8760764d378988"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
