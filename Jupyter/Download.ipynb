{
 "cells": [
  {
   "metadata": {
    "tags": [
     "Initialization"
    ]
   },
   "cell_type": "markdown",
   "source": [
    "# Setup\n",
    "Configuration, Logger, Counter and Downloader"
   ],
   "id": "b2f2a0d6e7bd322b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T15:23:56.986516Z",
     "start_time": "2025-10-20T15:23:56.637184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from core.config import Config, split_in_chunks\n",
    "from data.download import LSEGDataDownloader\n",
    "\n",
    "os.environ[\"RD_LIB_CONFIG_PATH\"] = \"/Configuration\"\n",
    "\n",
    "config = Config()\n",
    "logging.basicConfig(\n",
    "        filename=config.log_file,\n",
    "        encoding=\"utf-8\",\n",
    "        level=config.log_level,\n",
    "        format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "        datefmt = '%Y-%m-%d %H:%M:%S'\n",
    "    )\n",
    "logger = logging.getLogger()"
   ],
   "id": "e74ca2369a377986",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Downloading time series Data",
   "id": "d595c661a33d1b36"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T15:26:52.885815Z",
     "start_time": "2025-10-20T15:23:58.070333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from core.exceptions import DataValidationError, DataDownloadError\n",
    "\n",
    "removed_companies: list[str] = []\n",
    "with open(config.removed_companies_file, \"r\") as file:\n",
    "    for line in file:\n",
    "        removed_companies.append(line.strip())\n",
    "\n",
    "companies: list[str] = [company for company in config.companies if removed_companies not in config.companies]\n",
    "companies_chunks: list[list[str]] = split_in_chunks(\n",
    "    companies,\n",
    "    chunk_size=config.companies_chunk_size_historic,\n",
    "    chunk_limit=config.chunk_limit\n",
    ")\n",
    "\n",
    "with (LSEGDataDownloader(config) as downloader):\n",
    "    for i, company_chunk in enumerate(config.companies_historic_chunks):\n",
    "        for attempt in range(2):\n",
    "            try:\n",
    "                print(f\"Downloading historic data: for {company_chunk[0]} to {company_chunk[-1]}\")\n",
    "                standardized_histordict: dict[str, pd.DataFrame] = downloader.download_historic_from(company_chunk, config.historic_features, i)\n",
    "                for key, new_df in standardized_histordict.items():\n",
    "                    new_df.to_csv(config.eda_filtered_historic_dir / f\"company-{key}.csv\")\n",
    "                break\n",
    "            except DataValidationError as e:\n",
    "                company_chunk.remove(e.__getcompanies__())\n",
    "                with open(config.removed_companies_file, \"a\") as file:\n",
    "                    file.write(f\"\\n{e.__getcompanies__()}\")\n",
    "                print(f\"Removed {e.__getcompanies__()} Try again.\")\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading historic data: {company_chunk}\")\n",
    "        else:\n",
    "            raise DataDownloadError(\"Too many attempts to download historic data\", company_chunk)"
   ],
   "id": "8ea3a8e6266ce6f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading historic data: for 000063.SZ to 068270.KS\n",
      "Error downloading historic data: ['000063.SZ', '000100.KS', '000120.KS', '000150.KS', '0002.HK', '000210.KS', '000270.KS', '0004.HK', '000660.KS', '000720.KS', '000810.KS', '000880.KS', '000895.SZ', '0010.HK', '0012.HK', '0013.HK', '001740.KS', '0019.HK', '002129.SZ', '002340.SZ', '002352.SZ', '002380.KS', '002459.SZ', '002475.SZ', '002506.SZ', '002555.SZ', '002790.KS', '002797.SZ', '002916.SZ', '002939.SZ', '003550.KS', '003670.KS', '004000.KS', '004020.KS', '005300.KS', '005380.KS', '005490.KS', '005930.KS', '005940.KS', '006360.KS', '006400.KS', '006800.KS', '007310.KS', '0083.HK', '009150.KS', '009240.KS', '009540.KS', '009830.KS', '010060.KS', '0101.HK', '010130.KS', '010140.KS', '010620.KS', '011070.KS', '011170.KS', '011200.KS', '011790.KS', '012330.KS', '012450.KS', '015760.KS', '016360.KS', '0175.HK', '017670.KS', '018260.KS', '018880.KS', '0200.HK', '021240.KS', '023530.KS', '024110.KS', '028050.KS', '028260.KS', '028670.KS', '0288.HK', '0293.HK', '029780.KS', '030200.KS', '0316.HK', '032640.KS', '032830.KS', '0330.HK', '033780.KS', '034220.KS', '0345.HK', '034730.KS', '035420.KS', '035720.KS', '036460.KS', '036570.KS', '0384.HK', '0388.HK', '042660.KS', '042670.KS', '047040.KS', '047050.KS', '051900.KS', '051910.KS', '055550.KS', '0656.HK', '066570.KS', '068270.KS']\n",
      "Downloading historic data: for 000063.SZ to 068270.KS\n",
      "Error downloading historic data: ['000063.SZ', '000100.KS', '000120.KS', '000150.KS', '0002.HK', '000210.KS', '000270.KS', '0004.HK', '000660.KS', '000720.KS', '000810.KS', '000880.KS', '000895.SZ', '0010.HK', '0012.HK', '0013.HK', '001740.KS', '0019.HK', '002129.SZ', '002340.SZ', '002352.SZ', '002380.KS', '002459.SZ', '002475.SZ', '002506.SZ', '002555.SZ', '002790.KS', '002797.SZ', '002916.SZ', '002939.SZ', '003550.KS', '003670.KS', '004000.KS', '004020.KS', '005300.KS', '005380.KS', '005490.KS', '005930.KS', '005940.KS', '006360.KS', '006400.KS', '006800.KS', '007310.KS', '0083.HK', '009150.KS', '009240.KS', '009540.KS', '009830.KS', '010060.KS', '0101.HK', '010130.KS', '010140.KS', '010620.KS', '011070.KS', '011170.KS', '011200.KS', '011790.KS', '012330.KS', '012450.KS', '015760.KS', '016360.KS', '0175.HK', '017670.KS', '018260.KS', '018880.KS', '0200.HK', '021240.KS', '023530.KS', '024110.KS', '028050.KS', '028260.KS', '028670.KS', '0288.HK', '0293.HK', '029780.KS', '030200.KS', '0316.HK', '032640.KS', '032830.KS', '0330.HK', '033780.KS', '034220.KS', '0345.HK', '034730.KS', '035420.KS', '035720.KS', '036460.KS', '036570.KS', '0384.HK', '0388.HK', '042660.KS', '042670.KS', '047040.KS', '047050.KS', '051900.KS', '051910.KS', '055550.KS', '0656.HK', '066570.KS', '068270.KS']\n"
     ]
    },
    {
     "ename": "DataDownloadError",
     "evalue": "Connection failed for ['000063.SZ', '000100.KS', '000120.KS', '000150.KS', '0002.HK', '000210.KS', '000270.KS', '0004.HK', '000660.KS', '000720.KS', '000810.KS', '000880.KS', '000895.SZ', '0010.HK', '0012.HK', '0013.HK', '001740.KS', '0019.HK', '002129.SZ', '002340.SZ', '002352.SZ', '002380.KS', '002459.SZ', '002475.SZ', '002506.SZ', '002555.SZ', '002790.KS', '002797.SZ', '002916.SZ', '002939.SZ', '003550.KS', '003670.KS', '004000.KS', '004020.KS', '005300.KS', '005380.KS', '005490.KS', '005930.KS', '005940.KS', '006360.KS', '006400.KS', '006800.KS', '007310.KS', '0083.HK', '009150.KS', '009240.KS', '009540.KS', '009830.KS', '010060.KS', '0101.HK', '010130.KS', '010140.KS', '010620.KS', '011070.KS', '011170.KS', '011200.KS', '011790.KS', '012330.KS', '012450.KS', '015760.KS', '016360.KS', '0175.HK', '017670.KS', '018260.KS', '018880.KS', '0200.HK', '021240.KS', '023530.KS', '024110.KS', '028050.KS', '028260.KS', '028670.KS', '0288.HK', '0293.HK', '029780.KS', '030200.KS', '0316.HK', '032640.KS', '032830.KS', '0330.HK', '033780.KS', '034220.KS', '0345.HK', '034730.KS', '035420.KS', '035720.KS', '036460.KS', '036570.KS', '0384.HK', '0388.HK', '042660.KS', '042670.KS', '047040.KS', '047050.KS', '051900.KS', '051910.KS', '055550.KS', '0656.HK', '066570.KS', '068270.KS'] with []",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mDataDownloadError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 33\u001B[39m\n\u001B[32m     31\u001B[39m         \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mError downloading historic data: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcompany_chunk\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     32\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m33\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m DataDownloadError(\u001B[33m\"\u001B[39m\u001B[33mToo many attempts to download historic data\u001B[39m\u001B[33m\"\u001B[39m, company_chunk)\n",
      "\u001B[31mDataDownloadError\u001B[39m: Connection failed for ['000063.SZ', '000100.KS', '000120.KS', '000150.KS', '0002.HK', '000210.KS', '000270.KS', '0004.HK', '000660.KS', '000720.KS', '000810.KS', '000880.KS', '000895.SZ', '0010.HK', '0012.HK', '0013.HK', '001740.KS', '0019.HK', '002129.SZ', '002340.SZ', '002352.SZ', '002380.KS', '002459.SZ', '002475.SZ', '002506.SZ', '002555.SZ', '002790.KS', '002797.SZ', '002916.SZ', '002939.SZ', '003550.KS', '003670.KS', '004000.KS', '004020.KS', '005300.KS', '005380.KS', '005490.KS', '005930.KS', '005940.KS', '006360.KS', '006400.KS', '006800.KS', '007310.KS', '0083.HK', '009150.KS', '009240.KS', '009540.KS', '009830.KS', '010060.KS', '0101.HK', '010130.KS', '010140.KS', '010620.KS', '011070.KS', '011170.KS', '011200.KS', '011790.KS', '012330.KS', '012450.KS', '015760.KS', '016360.KS', '0175.HK', '017670.KS', '018260.KS', '018880.KS', '0200.HK', '021240.KS', '023530.KS', '024110.KS', '028050.KS', '028260.KS', '028670.KS', '0288.HK', '0293.HK', '029780.KS', '030200.KS', '0316.HK', '032640.KS', '032830.KS', '0330.HK', '033780.KS', '034220.KS', '0345.HK', '034730.KS', '035420.KS', '035720.KS', '036460.KS', '036570.KS', '0384.HK', '0388.HK', '042660.KS', '042670.KS', '047040.KS', '047050.KS', '051900.KS', '051910.KS', '055550.KS', '0656.HK', '066570.KS', '068270.KS'] with []"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Downloading static Data",
   "id": "9391c4d8701b8b7e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from core.exceptions import DataValidationError, DataDownloadError\n",
    "\n",
    "removed_companies: list[str] = []\n",
    "with open(config.removed_companies_file, \"r\") as file:\n",
    "    for line in file:\n",
    "        removed_companies.append(line.strip())\n",
    "\n",
    "companies: list[str] = [company for company in config.companies if removed_companies not in config.companies]\n",
    "companies_chunks: list[list[str]] = split_in_chunks(\n",
    "    companies,\n",
    "    chunk_size=config.companies_chunk_size_static,\n",
    "    chunk_limit=config.chunk_limit\n",
    ")\n",
    "\n",
    "with LSEGDataDownloader(config) as downloader:\n",
    "    for i, company_chunk in enumerate(companies_chunks):\n",
    "        for attempt in range(100):\n",
    "            try:\n",
    "                print(f\"Downloading static data: for {company_chunk[0]} to {company_chunk[-1]}\")\n",
    "                statdict: dict[str, pd.DataFrame] = downloader.download_static_from(company_chunk, config.static_features)\n",
    "                for name, frame in statdict.items():\n",
    "                    frame.to_csv(config.filtered_static_dir / f\"company-{name}.csv\")\n",
    "                break\n",
    "            except DataValidationError as e:\n",
    "                company_chunk.remove(e.__getcompanies__())\n",
    "                with open(config.removed_companies_file, \"a\") as file:\n",
    "                    file.write(f\"\\n{e.__getcompanies__()}\")\n",
    "                print(f\"Removed {e.__getcompanies__()} Try again.\")\n",
    "                continue\n",
    "        else:\n",
    "            raise DataDownloadError(\"Too many attempts to download static data\", company_chunk)"
   ],
   "id": "d079e5f6a397e8e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Other",
   "id": "d31627d883df066c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "dir1 = config.dataset_dir / \"historic\"\n",
    "dir2 = config.dataset_dir / \"static\"\n",
    "files1: list[str] = [file.name for file in dir1.glob(\"*.csv\")]\n",
    "names1: list[str] = [re.findall(r\"company-+(.*).csv\", file)[0] for file in files1]\n",
    "files2: list[str] = [file.name for file in dir2.glob(\"*.csv\")]\n",
    "names2: list[str] = [re.findall(r\"company-+(.*).csv\", file)[0] for file in files2]\n",
    "not_in1: list[str] = [name for name in names2 if name not in names1]\n",
    "not_in2: list[str] = [name for name in names1 if name not in names2]\n",
    "not_in_both: list[str] = not_in1 + not_in2"
   ],
   "id": "c05e6e49fdb3dfec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def is_unique(s: pd.DataFrame):\n",
    "    a: np.ndarray = s.to_numpy()\n",
    "    return (a[0] == a).all()\n",
    "without_same_results: pd.DataFrame = all_static_frame[all_static_frame.apply(is_unique, axis=1)]"
   ],
   "id": "4ba2bfd890724108",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
