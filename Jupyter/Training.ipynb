{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Writing all_data CSV",
   "id": "77729406c16340df"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "from core import Config\n",
    "\n",
    "config = Config()\n",
    "\n",
    "HISTORIC_PATH = config.eda_filtered_dir / \"eda_filtered_historic.csv\"\n",
    "HISTORIC_DTYPES_PATH = config.eda_filtered_dir / \"eda_filtered_historic_dtypes.csv\"\n",
    "STATIC_PATH = config.eda_filtered_dir / \"eda_filtered_static.csv\"\n",
    "STATIC_DTYPES_PATH = config.eda_filtered_dir / \"eda_filtered_static_dtypes.csv\"\n",
    "\n",
    "def _read_dtype_map(path) -> dict[str, str]:\n",
    "    dtypes_df: pd.DataFrame = pd.read_csv(path, index_col=1)\n",
    "    return dtypes_df.iloc[:, 1].to_dict()\n",
    "\n",
    "historic_dtypes: dict[str, str] = _read_dtype_map(HISTORIC_DTYPES_PATH)\n",
    "static_dtypes: dict[str, str] = _read_dtype_map(STATIC_DTYPES_PATH)\n",
    "\n",
    "historic_df: pd.DataFrame = pd.read_csv(\n",
    "    HISTORIC_PATH,\n",
    "    index_col=[0, 1],\n",
    "    dtype=historic_dtypes\n",
    ")\n",
    "static_df: pd.DataFrame = pd.read_csv(\n",
    "    STATIC_PATH,\n",
    "    index_col=0,\n",
    "    dtype=static_dtypes\n",
    ")\n",
    "\n",
    "instrument_index = historic_df.index.get_level_values(0)\n",
    "static_aligned = static_df.reindex(instrument_index)\n",
    "static_aligned.index = historic_df.index\n",
    "\n",
    "all_data: pd.DataFrame = pd.concat([historic_df, static_aligned], axis=1)\n",
    "\n",
    "del historic_df, static_aligned, static_df, instrument_index, static_dtypes, historic_dtypes, HISTORIC_DTYPES_PATH, STATIC_PATH, HISTORIC_PATH, STATIC_DTYPES_PATH\n",
    "import gc\n",
    "gc.collect()"
   ],
   "id": "d8360fb87173ef89",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "all_data.to_csv(config.dataset_dir / 'all_data.csv')",
   "id": "3dc19bba553bca9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loading All Data",
   "id": "eb436741cc069b77"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T13:02:28.182691Z",
     "start_time": "2026-02-16T13:02:27.137299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from core import Config\n",
    "config = Config()\n",
    "all_data = pd.read_csv(config.dataset_dir / 'all_data.csv', index_col=[0, 1])"
   ],
   "id": "1aa732ce7902eb95",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Split Training and Validation Set",
   "id": "7e7d3440e40fbd20"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T13:04:27.155560Z",
     "start_time": "2026-02-16T13:04:26.110328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_data: pd.DataFrame = all_data.reset_index()\n",
    "training_data = training_data.convert_dtypes()\n",
    "training_data.drop(training_data[training_data[\"TR.UpstreamScope3PurchasedGoodsAndServices\"].isna()].index, inplace=True)\n",
    "y: pd.DataFrame = training_data['TR.UpstreamScope3PurchasedGoodsAndServices'].to_frame()\n",
    "X: pd.DataFrame = training_data.drop('TR.UpstreamScope3PurchasedGoodsAndServices', axis=1)"
   ],
   "id": "81edf05a14da4429",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2h/zzz_kcts3f3gs5mh257zw7zw0000gn/T/ipykernel_62644/4162779444.py:1:PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T13:04:28.908846Z",
     "start_time": "2026-02-16T13:04:28.828135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "group_types = X.columns.to_series().groupby(X.dtypes.apply(lambda x: x.name))\n",
    "string_columns = group_types.get_group('string')\n",
    "boolean_columns = group_types.get_group('boolean')\n",
    "float_columns = group_types.get_group('Float64')\n",
    "int_columns = group_types.get_group('Int64')\n",
    "\n",
    "X[string_columns] = X[string_columns].fillna('missing')\n",
    "X[boolean_columns] = X[boolean_columns].fillna(False)\n",
    "X[float_columns] = X[float_columns].fillna(0)\n",
    "X[int_columns] = X[int_columns].fillna(0)\n",
    "\n",
    "X[string_columns] = X[string_columns].astype('category')\n",
    "cat_features = [X.columns.get_loc(c) for c in string_columns if c in X]\n",
    "\n",
    "y = y.fillna(0)"
   ],
   "id": "d1dc04d3bf0846cc",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from catboost import Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_validation, y_train, y_validation = data\n",
    "train_pool = Pool(\n",
    "    data=X_train,\n",
    "    label=y_train,\n",
    "    cat_features=cat_features\n",
    ")\n",
    "validation_pool = Pool(\n",
    "    data=X_validation,\n",
    "    label=y_validation,\n",
    "    cat_features=cat_features\n",
    ")"
   ],
   "id": "6275d10e543a2d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "del all_data, boolean_columns, float_columns, int_columns, string_columns, historic_frame, static_frame, static_dtypes, group_types, config, training_data\n",
    "import gc\n",
    "gc.collect()"
   ],
   "id": "f98f220f0ba521ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from catboost import CatBoostRegressor\n",
    "model = CatBoostRegressor(iterations=1000, nan_mode='Min')\n",
    "model.fit(train_pool, eval_set=validation_pool, verbose=True, plot=True)"
   ],
   "id": "8419b4ab0169af72",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
